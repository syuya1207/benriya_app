import logging
import os
from datetime import datetime
from typing import List, Dict, Any, Optional
import csv 
import sys 

from dotenv import load_dotenv

# PostgreSQLã¨ã®æ¥ç¶šã«psycopg2ã‚’ä½¿ç”¨ (venvã«ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ¸ˆã¿ã¨ä»®å®š)
try:
    import psycopg2 
    from psycopg2.extras import DictCursor
except ImportError:
    # psycopg2ãŒãªã„å ´åˆã¯ã€DBæ¥ç¶šãƒ†ã‚¹ãƒˆã¯ã‚¹ã‚­ãƒƒãƒ—ã•ã‚Œã‚‹ã‚ˆã†ã«ã™ã‚‹
    print("Warning: psycopg2-binary is not installed. DB connection test will be skipped.", file=sys.stderr)
    psycopg2 = None

# ç’°å¢ƒå¤‰æ•°ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰èª­ã¿è¾¼ã‚€
load_dotenv()
    
# ----------------------------------------------------------------------
# å¿…è¦ãªå®šæ•°
# ----------------------------------------------------------------------
# ç’°å¢ƒå¤‰æ•°ã‹ã‚‰å–å¾—
DATABASE_URL = os.getenv("DATABASE_URL")

# ãƒ­ã‚°è¨­å®š: æ¨™æº–ã‚¨ãƒ©ãƒ¼ã«å‡ºåŠ›ã€‚INFOãƒ¬ãƒ™ãƒ«ä»¥ä¸Šã‚’è¡¨ç¤ºã€‚
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s', stream=sys.stderr)
logger = logging.getLogger(__name__)

# ç§»è¡Œå¯¾è±¡ã®CSVãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ (ãƒ¦ãƒ¼ã‚¶ãƒ¼æƒ…å ±)
CSV_FILE = "data/user_data.csv" 

# ----------------------------------------------------------------------
# ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°
# ----------------------------------------------------------------------
def _parse_timestamp(timestamp_str: str) -> Optional[datetime]:
    """æ—¥æ™‚æ–‡å­—åˆ—ã‚’datetimeã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã«å¤‰æ›ã€‚ç©ºæ–‡å­—åˆ—ã®å ´åˆã¯Noneã‚’è¿”ã™ã€‚"""
    if not timestamp_str or timestamp_str.strip() == '':
        return None
    
    # æ··åœ¨ã™ã‚‹æ—¥æ™‚ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã«å¯¾å¿œï¼ˆãƒã‚¤ãƒ•ãƒ³/ã‚¹ãƒ©ãƒƒã‚·ãƒ¥ã®ã©ã¡ã‚‰ã‹ï¼‰
    timestamp_str = timestamp_str.strip()
    
    # è©¦è¡Œ1: ãƒã‚¤ãƒ•ãƒ³åŒºåˆ‡ã‚Š (%Y-%m-%d %H:%M:%S)
    try:
        return datetime.strptime(timestamp_str, "%Y-%m-%d %H:%M:%S")
    except ValueError:
        pass
    
    # è©¦è¡Œ2: ã‚¹ãƒ©ãƒƒã‚·ãƒ¥åŒºåˆ‡ã‚Š (%Y/%m/%d %H:%M:%S)
    try:
        return datetime.strptime(timestamp_str, "%Y/%m/%d %H:%M:%S")
    except ValueError:
        pass

    # ã©ã¡ã‚‰ã‚‚å¤±æ•—ã—ãŸå ´åˆã¯ã‚¨ãƒ©ãƒ¼
    raise ValueError(f"æ—¥æ™‚å½¢å¼ãŒä¸æ­£ã§ã™: {timestamp_str}")


# ----------------------------------------------------------------------
# DBæ“ä½œé–¢æ•° (ãƒ†ã‚¹ãƒˆç”¨: æ¥ç¶šãƒã‚§ãƒƒã‚¯ã®ã¿)
# ----------------------------------------------------------------------
def check_db_connection():
    """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šã®å¯å¦ã‚’ãƒ†ã‚¹ãƒˆã™ã‚‹é–¢æ•°ã€‚"""
    if not psycopg2:
        logger.warning("DBæ¥ç¶šãƒ†ã‚¹ãƒˆ: psycopg2ãŒãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ãªã„ãŸã‚ã€ãƒ†ã‚¹ãƒˆã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
        return False
        
    if not DATABASE_URL:
        logger.error("DBæ¥ç¶šãƒ†ã‚¹ãƒˆ: DATABASE_URLãŒç’°å¢ƒå¤‰æ•°ã«è¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        return False

    conn = None
    try:
        conn = psycopg2.connect(DATABASE_URL)
        logger.info("DBæ¥ç¶šãƒ†ã‚¹ãƒˆ: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šã«æˆåŠŸã—ã¾ã—ãŸã€‚")
        return True
        
    except psycopg2.Error as e:
        logger.error(f"FATAL: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return False
        
    finally:
        if conn:
            conn.close() 

# ----------------------------------------------------------------------
# ãƒ‡ãƒ¼ã‚¿å–å¾—é–¢æ•° (CSVèª­ã¿è¾¼ã¿)
# ----------------------------------------------------------------------
def fetch_csv_data() -> List[Dict[str, Any]]:
    """CSVãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã™ã‚‹ã€‚"""
    logger.info(f"ãƒ‡ãƒ¼ã‚¿å–å¾—: CSVãƒ•ã‚¡ã‚¤ãƒ« '{CSV_FILE}' ã®èª­ã¿è¾¼ã¿ã‚’é–‹å§‹ã—ã¾ã™ã€‚")
    data = []
    
    if not os.path.exists(CSV_FILE):
        logger.error(f"ã‚¨ãƒ©ãƒ¼: CSVãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {CSV_FILE}")
        return []

    try:
        with open(CSV_FILE, mode='r', encoding='utf-8') as f:
            csv_reader = csv.DictReader(f)
            for row in csv_reader:
                # è¾æ›¸ã®ã‚³ãƒ”ãƒ¼ã‚’ä½œæˆã—ã€å…ƒã®DictReaderã®æŒ™å‹•ã«ä¾å­˜ã—ãªã„ã‚ˆã†ã«ã™ã‚‹
                data.append(dict(row))
        
        logger.info(f"ãƒ‡ãƒ¼ã‚¿å–å¾—: æˆåŠŸã€‚åˆè¨ˆ {len(data)} è¡Œã®ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ãŸã€‚")
        return data
        
    except Exception as e:
        logger.error(f"è‡´å‘½çš„ã‚¨ãƒ©ãƒ¼: CSVãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        return []

# ----------------------------------------------------------------------
# ç§»è¡Œé–¢æ•° (ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ‡ãƒ¼ã‚¿æ•´å½¢ã¨ãƒ­ã‚°å‡ºåŠ›ã®ãƒ†ã‚¹ãƒˆ)
# ----------------------------------------------------------------------
def migrate_data():
    """CSVãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã€PostgreSQLã®usersãƒ†ãƒ¼ãƒ–ãƒ«ã®å‹ã«åˆã†ã‹ãƒ†ã‚¹ãƒˆã™ã‚‹ã€‚"""
    
    logger.info("--- ãƒ¦ãƒ¼ã‚¶ãƒ¼ç§»è¡Œãƒ†ã‚¹ãƒˆé–‹å§‹ (CSVèª­ã¿è¾¼ã¿ & ãƒ‡ãƒ¼ã‚¿å‹æ•´å½¢ãƒã‚§ãƒƒã‚¯) ---")
    
    data = fetch_csv_data()
    
    if not data:
        return False

    success_count = 0
    
    # å¿…é ˆã®CSVãƒ˜ãƒƒãƒ€ãƒ¼å®šç¾©
    REQUIRED_HEADERS = ['ãƒ¦ãƒ¼ã‚¶ãƒ¼ID', 'å­¦å¹´', 'ã‚¯ãƒ©ã‚¹', 'å§“', 'å', 'ãƒ¦ãƒ¼ã‚¶ãƒ¼å', 'ç™»éŒ²æ—¥æ™‚']

    for row in data:
        try:
            # 1. å¿…é ˆã‚«ãƒ©ãƒ ã®å­˜åœ¨ãƒã‚§ãƒƒã‚¯ (KeyErrorã§æ•æ‰ã•ã‚Œã‚‹)
            user_line_id = row['ãƒ¦ãƒ¼ã‚¶ãƒ¼ID'] 
            user_grade = row['å­¦å¹´']
            user_class = row['ã‚¯ãƒ©ã‚¹']
            user_last_name = row['å§“']
            user_first_name = row['å']
            user_line_name = row['ãƒ¦ãƒ¼ã‚¶ãƒ¼å']
            
            # 2. æ—¥æ™‚ã‚«ãƒ©ãƒ ã®å¤‰æ› (å¿…é ˆ/ä»»æ„)
            # 'ç™»éŒ²æ—¥æ™‚' ã¯å¿…é ˆï¼ˆç©ºæ–‡å­—åˆ—ã¯è¨±å¯ã—ãªã„ï¼‰
            user_registered_at = _parse_timestamp(row['ç™»éŒ²æ—¥æ™‚'])
            if user_registered_at is None:
                raise ValueError("'ç™»éŒ²æ—¥æ™‚'ãŒç©ºã§ã™ã€‚å¿…é ˆé …ç›®ã§ã™ã€‚")

            # 'æ›´æ–°æ—¥', 'é€šçŸ¥åœæ­¢æ—¥', 'å‰Šé™¤æ—¥' ã¯ä»»æ„ï¼ˆç©ºæ–‡å­—åˆ—ã¯Noneã«å¤‰æ›ï¼‰
            user_updated_at = _parse_timestamp(row.get('æ›´æ–°æ—¥', ''))
            user_notification_stopped_at = _parse_timestamp(row.get('é€šçŸ¥åœæ­¢æ—¥', ''))
            user_deleted_at = _parse_timestamp(row.get('å‰Šé™¤æ—¥', ''))
            
            # 3. DBã«æŒ¿å…¥ã•ã‚Œã‚‹æƒ³å®šã®ãƒ‡ãƒ¼ã‚¿æ§‹é€ 
            validated_user_data = {
                # user_id ã¯ SERIAL ãªã®ã§å«ã‚ãªã„
                'user_line_id': user_line_id, 
                'user_grade': user_grade,
                'user_class': user_class,
                'user_last_name': user_last_name,
                'user_first_name': user_first_name,
                'user_line_name': user_line_name,
                
                # æ—¥æ™‚ãƒ‡ãƒ¼ã‚¿
                'user_registered_at': user_registered_at,
                'user_updated_at': user_updated_at,
                'user_notification_stopped_at': user_notification_stopped_at,
                'user_deleted_at': user_deleted_at,
                
                # âš ï¸ CSVã«ãªã„é …ç›®: user_email, user_password_hash, user_typeãªã©ã¯ã“ã“ã§ã¯Noneã¨ã—ã¦æ‰±ã† (NULLè¨±å®¹ã®å ´åˆ)
                'user_email': None,
                'user_password_hash': None,
                'user_type': 'external', # ä¾‹: å¤–éƒ¨ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã®ç§»è¡Œã‚’ç¤ºã™
            }

            # ğŸš¨ æ•´å½¢çµæœã‚’ãƒ­ã‚°ã«å‡ºåŠ›ã—ã¦ç¢ºèª (DEBUGãƒ¬ãƒ™ãƒ«ãªã®ã§é€šå¸¸ã¯éè¡¨ç¤º)
            logger.debug(f"TEST SUCCESS: ID='{user_line_id}', Grade='{user_grade}', Registered={user_registered_at}, Deleted={user_deleted_at}")
            logger.debug(f"FULL DATA: {validated_user_data}")

            # ğŸš¨ å®Ÿéš›ã«ã¯ã“ã“ã« DBæ›¸ãè¾¼ã¿ãƒ­ã‚¸ãƒƒã‚¯ (INSERT INTO users ...) ãŒå…¥ã‚‹
            success_count += 1
            
        except KeyError as e:
            # ãƒ˜ãƒƒãƒ€ãƒ¼ãŒåˆã‚ãªã„å ´åˆã¯ã€è‡´å‘½çš„ã‚¨ãƒ©ãƒ¼ã¨ã—ã¦çµ‚äº†
            logger.error(f"FATAL: CSVãƒ˜ãƒƒãƒ€ãƒ¼ã‚¨ãƒ©ãƒ¼ã€‚å¿…è¦ãªã‚«ãƒ©ãƒ  {e} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
            logger.error(f"æƒ³å®šãƒ˜ãƒƒãƒ€ãƒ¼: {REQUIRED_HEADERS}")
            return False 
        except ValueError as e:
            # ãƒ‡ãƒ¼ã‚¿å‹å¤‰æ›ãŒå¤±æ•—ã—ãŸå ´åˆã¯ã€ãã®è¡Œã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¦ãƒ­ã‚°ã«å‡ºåŠ› (ERRORãƒ¬ãƒ™ãƒ«)
            logger.error(f"SKIP: ãƒ‡ãƒ¼ã‚¿å‹å¤‰æ›ã‚¨ãƒ©ãƒ¼ã€‚ãƒ‡ãƒ¼ã‚¿: {row}ã€ã‚¨ãƒ©ãƒ¼: {e}")
            
    logger.info(f"ãƒ¦ãƒ¼ã‚¶ãƒ¼ç§»è¡Œãƒ†ã‚¹ãƒˆå®Œäº†ã€‚æ­£å¸¸ã«æ•´å½¢ã•ã‚ŒãŸè¡Œæ•°: {success_count} / å…¨è¡Œæ•°: {len(data)}")
    return True


def run_test():
    """å…¨ã¦ã®ãƒ†ã‚¹ãƒˆå‡¦ç†ã‚’å®Ÿè¡Œã™ã‚‹ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    logger.info("========================================")
    logger.info("--- ãƒ¦ãƒ¼ã‚¶ãƒ¼ç§»è¡Œãƒ†ã‚¹ãƒˆã‚¹ã‚¯ãƒªãƒ—ãƒˆå®Ÿè¡Œ ---")
    
    # 1. DBæ¥ç¶šãƒ†ã‚¹ãƒˆ
    db_ok = check_db_connection()
    if db_ok:
        logger.info("ã‚¹ãƒ†ãƒƒãƒ— 1/2: DBæ¥ç¶šãƒ†ã‚¹ãƒˆæˆåŠŸã€‚")
    else:
        logger.warning("ã‚¹ãƒ†ãƒƒãƒ— 1/2: DBæ¥ç¶šãƒ†ã‚¹ãƒˆã‚¹ã‚­ãƒƒãƒ—ã¾ãŸã¯å¤±æ•—ã€‚ç¶šè¡Œã—ã¾ã™ã€‚")
        
    # 2. CSVèª­ã¿è¾¼ã¿ã¨ãƒ‡ãƒ¼ã‚¿æ•´å½¢ãƒ†ã‚¹ãƒˆ
    if migrate_data():
        logger.info("ã‚¹ãƒ†ãƒƒãƒ— 2/2: CSVèª­ã¿è¾¼ã¿ãƒ»ãƒ‡ãƒ¼ã‚¿æ•´å½¢ãƒ†ã‚¹ãƒˆæˆåŠŸã€‚")
    else:
        logger.error("ã‚¹ãƒ†ãƒƒãƒ— 2/2: CSVèª­ã¿è¾¼ã¿ãƒ»ãƒ‡ãƒ¼ã‚¿æ•´å½¢ãƒ†ã‚¹ãƒˆå¤±æ•—ã€‚")
        
    logger.info("--- å…¨ãƒ†ã‚¹ãƒˆå®Œäº† ---")
    logger.info("========================================")

if __name__ == '__main__':
    run_test()